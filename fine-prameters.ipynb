{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\misso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypermodel\n",
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperband is a hyperparameter tuning algorithm that aims to find the best configuration for your model efficiently.\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running multiple configurations in parallel: It starts by randomly sampling different hyperparameter values.\n",
    "Early stopping: It stops training models that perform poorly early on, saving time and resources.\n",
    "Adaptive allocation: It allocates more resources to promising configurations and fewer resources to less promising ones.\n",
    "Iterative process: It repeats these steps multiple times to refine its search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback to stop training early after reaching a certain value for the validation loss.\n",
    "# if the validation loss does not improve for 5 consecutive epochs, the training will be stopped early.\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stop_early:\n",
    "Prevents overfitting: By stopping training early, you can prevent the model from memorizing the training data too much and improve its ability to generalize to unseen data.\n",
    "Saves time and resources: Training large models can be time-consuming and resource-intensive. EarlyStopping helps you find a good model without wasting time training for unnecessary epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4924 - accuracy: 0.8245 - val_loss: 0.4265 - val_accuracy: 0.8461\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3726 - accuracy: 0.8644 - val_loss: 0.3788 - val_accuracy: 0.8612\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3338 - accuracy: 0.8772 - val_loss: 0.3435 - val_accuracy: 0.8777\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3085 - accuracy: 0.8855 - val_loss: 0.3620 - val_accuracy: 0.8703\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2869 - accuracy: 0.8932 - val_loss: 0.3262 - val_accuracy: 0.8802\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2701 - accuracy: 0.8990 - val_loss: 0.3197 - val_accuracy: 0.8852\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2590 - accuracy: 0.9029 - val_loss: 0.3118 - val_accuracy: 0.8893\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2465 - accuracy: 0.9078 - val_loss: 0.3276 - val_accuracy: 0.8795\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2338 - accuracy: 0.9112 - val_loss: 0.3401 - val_accuracy: 0.8833\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2244 - accuracy: 0.9153 - val_loss: 0.3214 - val_accuracy: 0.8898\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2149 - accuracy: 0.9192 - val_loss: 0.3207 - val_accuracy: 0.8921\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2072 - accuracy: 0.9217 - val_loss: 0.3271 - val_accuracy: 0.8869\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1997 - accuracy: 0.9244 - val_loss: 0.3402 - val_accuracy: 0.8887\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1909 - accuracy: 0.9290 - val_loss: 0.3182 - val_accuracy: 0.8936\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1845 - accuracy: 0.9299 - val_loss: 0.3253 - val_accuracy: 0.8923\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1786 - accuracy: 0.9321 - val_loss: 0.3229 - val_accuracy: 0.8938\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1720 - accuracy: 0.9349 - val_loss: 0.3699 - val_accuracy: 0.8892\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1679 - accuracy: 0.9364 - val_loss: 0.3415 - val_accuracy: 0.8908\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1612 - accuracy: 0.9397 - val_loss: 0.4003 - val_accuracy: 0.8852\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1582 - accuracy: 0.9400 - val_loss: 0.3590 - val_accuracy: 0.8913\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1515 - accuracy: 0.9433 - val_loss: 0.3490 - val_accuracy: 0.8941\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1453 - accuracy: 0.9444 - val_loss: 0.3709 - val_accuracy: 0.8931\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1441 - accuracy: 0.9453 - val_loss: 0.3494 - val_accuracy: 0.8941\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1374 - accuracy: 0.9483 - val_loss: 0.4021 - val_accuracy: 0.8901\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1348 - accuracy: 0.9494 - val_loss: 0.3653 - val_accuracy: 0.8963\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1288 - accuracy: 0.9515 - val_loss: 0.3886 - val_accuracy: 0.8954\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1279 - accuracy: 0.9507 - val_loss: 0.3842 - val_accuracy: 0.8961\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1223 - accuracy: 0.9527 - val_loss: 0.4058 - val_accuracy: 0.8912\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1212 - accuracy: 0.9540 - val_loss: 0.3858 - val_accuracy: 0.8923\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1140 - accuracy: 0.9572 - val_loss: 0.4136 - val_accuracy: 0.8918\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1138 - accuracy: 0.9574 - val_loss: 0.4235 - val_accuracy: 0.8937\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1140 - accuracy: 0.9568 - val_loss: 0.4122 - val_accuracy: 0.8953\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1101 - accuracy: 0.9586 - val_loss: 0.4268 - val_accuracy: 0.8940\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1050 - accuracy: 0.9599 - val_loss: 0.4558 - val_accuracy: 0.8902\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1035 - accuracy: 0.9622 - val_loss: 0.4205 - val_accuracy: 0.8948\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1025 - accuracy: 0.9616 - val_loss: 0.4238 - val_accuracy: 0.8941\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0952 - accuracy: 0.9645 - val_loss: 0.4423 - val_accuracy: 0.8951\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0956 - accuracy: 0.9643 - val_loss: 0.4570 - val_accuracy: 0.8953\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0943 - accuracy: 0.9643 - val_loss: 0.4550 - val_accuracy: 0.8933\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0935 - accuracy: 0.9647 - val_loss: 0.4943 - val_accuracy: 0.8884\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0879 - accuracy: 0.9665 - val_loss: 0.4742 - val_accuracy: 0.8938\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0867 - accuracy: 0.9679 - val_loss: 0.4809 - val_accuracy: 0.8958\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0857 - accuracy: 0.9682 - val_loss: 0.4842 - val_accuracy: 0.8953\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0860 - accuracy: 0.9678 - val_loss: 0.5337 - val_accuracy: 0.8898\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0843 - accuracy: 0.9681 - val_loss: 0.4879 - val_accuracy: 0.8959\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0803 - accuracy: 0.9700 - val_loss: 0.5208 - val_accuracy: 0.8923\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0788 - accuracy: 0.9698 - val_loss: 0.5149 - val_accuracy: 0.8941\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0765 - accuracy: 0.9718 - val_loss: 0.5394 - val_accuracy: 0.8924\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0775 - accuracy: 0.9711 - val_loss: 0.5466 - val_accuracy: 0.8917\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0753 - accuracy: 0.9719 - val_loss: 0.5016 - val_accuracy: 0.8968\n",
      "Best epoch: 50\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4912 - accuracy: 0.8256 - val_loss: 0.3845 - val_accuracy: 0.8622\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3684 - accuracy: 0.8660 - val_loss: 0.3774 - val_accuracy: 0.8627\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3300 - accuracy: 0.8796 - val_loss: 0.3674 - val_accuracy: 0.8657\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3062 - accuracy: 0.8865 - val_loss: 0.4176 - val_accuracy: 0.8503\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2840 - accuracy: 0.8952 - val_loss: 0.3420 - val_accuracy: 0.8779\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2696 - accuracy: 0.9005 - val_loss: 0.3377 - val_accuracy: 0.8800\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2553 - accuracy: 0.9051 - val_loss: 0.3143 - val_accuracy: 0.8888\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2448 - accuracy: 0.9082 - val_loss: 0.3127 - val_accuracy: 0.8868\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2346 - accuracy: 0.9120 - val_loss: 0.3179 - val_accuracy: 0.8922\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2231 - accuracy: 0.9152 - val_loss: 0.3238 - val_accuracy: 0.8895\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2135 - accuracy: 0.9193 - val_loss: 0.3469 - val_accuracy: 0.8810\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2059 - accuracy: 0.9227 - val_loss: 0.3261 - val_accuracy: 0.8928\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1999 - accuracy: 0.9243 - val_loss: 0.3393 - val_accuracy: 0.8860\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1922 - accuracy: 0.9277 - val_loss: 0.3530 - val_accuracy: 0.8838\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1846 - accuracy: 0.9307 - val_loss: 0.3323 - val_accuracy: 0.8915\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1789 - accuracy: 0.9331 - val_loss: 0.3366 - val_accuracy: 0.8897\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1722 - accuracy: 0.9355 - val_loss: 0.3497 - val_accuracy: 0.8900\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1659 - accuracy: 0.9360 - val_loss: 0.3325 - val_accuracy: 0.8933\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1595 - accuracy: 0.9402 - val_loss: 0.3672 - val_accuracy: 0.8888\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1572 - accuracy: 0.9410 - val_loss: 0.3586 - val_accuracy: 0.8953\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1508 - accuracy: 0.9428 - val_loss: 0.3515 - val_accuracy: 0.8971\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1477 - accuracy: 0.9437 - val_loss: 0.3876 - val_accuracy: 0.8882\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1414 - accuracy: 0.9466 - val_loss: 0.3812 - val_accuracy: 0.8891\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.1394 - accuracy: 0.9482 - val_loss: 0.3708 - val_accuracy: 0.8949\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1338 - accuracy: 0.9492 - val_loss: 0.3690 - val_accuracy: 0.8943\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1303 - accuracy: 0.9508 - val_loss: 0.3949 - val_accuracy: 0.8886\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1263 - accuracy: 0.9508 - val_loss: 0.3957 - val_accuracy: 0.8906\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1229 - accuracy: 0.9530 - val_loss: 0.4028 - val_accuracy: 0.8917\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1197 - accuracy: 0.9548 - val_loss: 0.3767 - val_accuracy: 0.8960\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1177 - accuracy: 0.9553 - val_loss: 0.3972 - val_accuracy: 0.8943\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1134 - accuracy: 0.9562 - val_loss: 0.4050 - val_accuracy: 0.8960\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1113 - accuracy: 0.9586 - val_loss: 0.4113 - val_accuracy: 0.8947\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1049 - accuracy: 0.9622 - val_loss: 0.4562 - val_accuracy: 0.8878\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1049 - accuracy: 0.9610 - val_loss: 0.4352 - val_accuracy: 0.8935\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1063 - accuracy: 0.9603 - val_loss: 0.4604 - val_accuracy: 0.8890\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0957 - accuracy: 0.9637 - val_loss: 0.4567 - val_accuracy: 0.8957\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0989 - accuracy: 0.9624 - val_loss: 0.4565 - val_accuracy: 0.8910\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0978 - accuracy: 0.9638 - val_loss: 0.4592 - val_accuracy: 0.8946\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0945 - accuracy: 0.9642 - val_loss: 0.4583 - val_accuracy: 0.8942\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0910 - accuracy: 0.9662 - val_loss: 0.4490 - val_accuracy: 0.8967\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0907 - accuracy: 0.9657 - val_loss: 0.4448 - val_accuracy: 0.8948\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0861 - accuracy: 0.9672 - val_loss: 0.4781 - val_accuracy: 0.8947\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0858 - accuracy: 0.9678 - val_loss: 0.4778 - val_accuracy: 0.8866\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0834 - accuracy: 0.9680 - val_loss: 0.5037 - val_accuracy: 0.8933\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0820 - accuracy: 0.9680 - val_loss: 0.4834 - val_accuracy: 0.8955\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0782 - accuracy: 0.9702 - val_loss: 0.5098 - val_accuracy: 0.8921\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0798 - accuracy: 0.9700 - val_loss: 0.5174 - val_accuracy: 0.8919\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0785 - accuracy: 0.9706 - val_loss: 0.5245 - val_accuracy: 0.8954\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0748 - accuracy: 0.9720 - val_loss: 0.5681 - val_accuracy: 0.8876\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0743 - accuracy: 0.9719 - val_loss: 0.5348 - val_accuracy: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2584babd890>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5919 - accuracy: 0.8911\n",
      "[test loss, test accuracy]: [0.591909646987915, 0.8910999894142151]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
